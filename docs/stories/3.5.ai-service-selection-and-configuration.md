# Story 3.5: AI Service Selection & Configuration

## Status

**Approved**

---

## Story

**As a** developer,
**I want** to finalize AI service selection (OpenAI vs Anthropic) and configure API access,
**so that** all AI features use a consistent, reliable AI provider.

---

## Acceptance Criteria

1. Decision made: OpenAI GPT-4 OR Anthropic Claude (based on API access availability)
2. API key obtained and stored in iOS Keychain (for direct testing) and Firebase env vars (for Cloud Functions)
3. Cloud Functions updated to use selected AI provider
4. Rate limiting implemented: Max 100 AI requests per user per day (configurable)
5. Cost tracking: Log AI requests to Firebase Analytics for cost monitoring
6. Error messages user-friendly: "AI service temporarily unavailable" instead of raw API errors
7. Fallback strategy: If AI service down, features gracefully disabled (not crash)
8. KeychainService wrapper created for secure API key storage in iOS
9. Documentation: README updated with AI provider details and setup instructions
10. Testing: All AI features tested with final provider, verify quality acceptable

---

## Previous Story Context

### Key Learnings from Story 3.1 (Cloud Functions Infrastructure)

**Cloud Functions Infrastructure Completed**:
- Three Cloud Functions created: `summarizeThread`, `extractActionItems`, `generateSmartSearchResults`
- Authentication and authorization validation implemented
- Cache lookup logic in place (checks `ai_cache` collection)
- Error handling framework established
- Placeholder AI API logic ready to be replaced

**Technical Patterns Established**:
- Function signature: `functions.https.onCall(async (data, context) => { ... })`
- Security checks: Verify `context.auth` and participant membership
- Cache key generation: `${featureType}_${conversationId}_${latestMessageId}`
- Error responses: Structured errors (`unauthenticated`, `permission-denied`, `internal`, etc.)
- Timeout configuration: 60 seconds max

**iOS Integration Ready**:
- `CloudFunctionsService.swift` created with methods to call all three functions
- Response DTOs defined (`SummaryResponse`, `ActionItemsResponse`, `SearchResultsResponse`)
- Error mapping from Cloud Functions to Swift errors
- Integration tests framework in place (requires emulator)

**What's Missing** (This Story Addresses):
- Actual AI API integration (currently placeholder logic)
- API key secure storage and management
- Rate limiting to prevent cost overruns
- Analytics tracking for cost monitoring
- Real AI quality validation

---

## Tasks / Subtasks

### Task 1: AI Provider Selection Decision (AC: 1)
- [ ] Evaluate OpenAI GPT-4 vs Anthropic Claude:
  - [ ] **Recommend OpenAI GPT-4 Turbo** for the following reasons:
    - Function calling support for structured outputs (action items, decisions)
    - Proven performance on summarization tasks
    - Larger context window (128k tokens)
    - Well-documented SDK
  - [ ] **Alternative: Anthropic Claude 3** if OpenAI unavailable:
    - Excellent summarization quality
    - Strong context understanding
    - Requires manual JSON parsing (no function calling as of now)
- [ ] Obtain API access:
  - [ ] Create OpenAI account: https://platform.openai.com/signup
  - [ ] Add payment method (required for API access)
  - [ ] Set spending limit: $20/month initially (can adjust based on usage)
  - [ ] Generate API key from dashboard
- [ ] Document decision in `docs/architecture/ai-provider.md`:
  - [ ] Selected provider and rationale
  - [ ] Model version: `gpt-4-turbo` (or `claude-3-opus-20240229`)
  - [ ] Pricing per request (estimate)
  - [ ] Rate limits imposed by provider
- [ ] Store API key securely (see Task 2 and Task 3)

### Task 2: Configure API Key in Firebase Cloud Functions (AC: 2, 3)
- [ ] Set environment variable in Firebase for dev environment:
  ```bash
  firebase functions:config:set openai.api_key="sk-..." --project=messageai-dev-1f2ec
  ```
- [ ] Set environment variable for prod environment:
  ```bash
  firebase functions:config:set openai.api_key="sk-..." --project=messageai-prod-4d3a8
  ```
- [ ] Verify configuration:
  ```bash
  firebase functions:config:get --project=messageai-dev-1f2ec
  ```
- [ ] Update `.gitignore` to exclude local runtime config:
  ```
  functions/.runtimeconfig.json
  ```
- [ ] For local testing, create `functions/.runtimeconfig.json`:
  ```json
  {
    "openai": {
      "api_key": "sk-..."
    }
  }
  ```
  (This file is gitignored, for local emulator testing only)

### Task 3: Implement KeychainService for iOS API Key Storage (AC: 2, 8)
- [ ] Create `MessageAI/Data/Services/KeychainService.swift`
- [ ] Implement KeychainService wrapper:
  ```swift
  import Security
  import Foundation

  class KeychainService {
      static let shared = KeychainService()

      private let serviceName = "com.messageai.app"

      func save(key: String, value: String) throws {
          let data = value.data(using: .utf8)!

          let query: [String: Any] = [
              kSecClass as String: kSecClassGenericPassword,
              kSecAttrService as String: serviceName,
              kSecAttrAccount as String: key,
              kSecValueData as String: data
          ]

          // Delete existing item
          SecItemDelete(query as CFDictionary)

          // Add new item
          let status = SecItemAdd(query as CFDictionary, nil)

          guard status == errSecSuccess else {
              throw KeychainError.saveFailed(status)
          }
      }

      func retrieve(key: String) throws -> String? {
          let query: [String: Any] = [
              kSecClass as String: kSecClassGenericPassword,
              kSecAttrService as String: serviceName,
              kSecAttrAccount as String: key,
              kSecReturnData as String: true
          ]

          var result: AnyObject?
          let status = SecItemCopyMatching(query as CFDictionary, &result)

          guard status == errSecSuccess,
                let data = result as? Data,
                let value = String(data: data, encoding: .utf8) else {
              if status == errSecItemNotFound {
                  return nil
              }
              throw KeychainError.retrieveFailed(status)
          }

          return value
      }

      func delete(key: String) throws {
          let query: [String: Any] = [
              kSecClass as String: kSecClassGenericPassword,
              kSecAttrService as String: serviceName,
              kSecAttrAccount as String: key
          ]

          let status = SecItemDelete(query as CFDictionary)

          guard status == errSecSuccess || status == errSecItemNotFound else {
              throw KeychainError.deleteFailed(status)
          }
      }
  }

  enum KeychainError: Error {
      case saveFailed(OSStatus)
      case retrieveFailed(OSStatus)
      case deleteFailed(OSStatus)
  }
  ```
- [ ] Add KeychainService to DIContainer (singleton)
- [ ] **Note**: iOS Keychain storage is for development/testing only. Production AI calls go through Cloud Functions (API key in Firebase environment variables).

### Task 4: Update Cloud Functions with OpenAI API Integration (AC: 3)
- [ ] Install OpenAI SDK in Cloud Functions:
  ```bash
  cd functions
  npm install openai
  ```
- [ ] Create `functions/src/utils/aiClient.ts`:
  ```typescript
  import OpenAI from 'openai';
  import * as functions from 'firebase-functions';

  let openaiClient: OpenAI | null = null;

  export function getOpenAIClient(): OpenAI {
    if (!openaiClient) {
      const apiKey = functions.config().openai?.api_key;

      if (!apiKey) {
        throw new functions.https.HttpsError(
          'failed-precondition',
          'OpenAI API key not configured'
        );
      }

      openaiClient = new OpenAI({
        apiKey: apiKey
      });
    }

    return openaiClient;
  }
  ```
- [ ] Update `functions/src/summarizeThread.ts` to call OpenAI:
  ```typescript
  import { getOpenAIClient } from './utils/aiClient';

  // Inside summarizeThread function, after fetching messages:
  const openai = getOpenAIClient();

  // Format messages for LLM
  const messagesText = messages.map(m =>
    `${m.senderName}: ${m.text}`
  ).join('\n');

  // Call OpenAI API
  const completion = await openai.chat.completions.create({
    model: 'gpt-4-turbo',
    messages: [
      {
        role: 'system',
        content: 'You are an AI assistant that summarizes team conversations. Focus on key decisions, action items, and important points. Keep summaries concise (150-300 words).'
      },
      {
        role: 'user',
        content: `Summarize this team conversation:\n\n${messagesText}`
      }
    ],
    temperature: 0.3,  // Lower temperature = more deterministic
    max_tokens: 500
  });

  const summary = completion.choices[0].message.content;
  ```
- [ ] Update `functions/src/extractActionItems.ts` to use OpenAI Function Calling:
  ```typescript
  const completion = await openai.chat.completions.create({
    model: 'gpt-4-turbo',
    messages: [
      {
        role: 'system',
        content: 'Extract action items from team conversations. Identify tasks, assignees, and deadlines.'
      },
      {
        role: 'user',
        content: `Extract action items from this conversation:\n\n${messagesText}`
      }
    ],
    tools: [{
      type: 'function',
      function: {
        name: 'extract_action_items',
        description: 'Extract action items from conversation',
        parameters: {
          type: 'object',
          properties: {
            actionItems: {
              type: 'array',
              items: {
                type: 'object',
                properties: {
                  task: { type: 'string', description: 'What needs to be done' },
                  assignee: { type: 'string', description: 'Who should do it (or "Unassigned")' },
                  deadline: { type: 'string', description: 'Due date if mentioned (or null)' },
                  sourceMessageId: { type: 'string', description: 'Message ID where task was mentioned' }
                },
                required: ['task', 'assignee']
              }
            }
          }
        }
      }
    }],
    tool_choice: { type: 'function', function: { name: 'extract_action_items' } }
  });

  const functionCall = completion.choices[0].message.tool_calls?.[0];
  const actionItems = JSON.parse(functionCall.function.arguments).actionItems;
  ```
- [ ] Update `functions/src/generateSmartSearchResults.ts` with semantic ranking:
  ```typescript
  const completion = await openai.chat.completions.create({
    model: 'gpt-4-turbo',
    messages: [
      {
        role: 'system',
        content: 'Rank messages by relevance to search query. Return top 10 most relevant.'
      },
      {
        role: 'user',
        content: `Query: "${query}"\n\nMessages:\n${messagesText}\n\nReturn message IDs ranked by relevance.`
      }
    ],
    temperature: 0.2,
    max_tokens: 300
  });
  ```
- [ ] Add error handling for OpenAI-specific errors:
  - [ ] Rate limit (HTTP 429) → `resource-exhausted`
  - [ ] Invalid API key (HTTP 401) → `failed-precondition`
  - [ ] Timeout → `deadline-exceeded`
  - [ ] Content policy violation → `invalid-argument`

### Task 5: Implement Rate Limiting in Cloud Functions (AC: 4)
- [ ] Create `functions/src/utils/rateLimiter.ts`:
  ```typescript
  import * as admin from 'firebase-admin';
  import * as functions from 'firebase-functions';

  const MAX_REQUESTS_PER_DAY = 100;

  export async function checkRateLimit(userId: string): Promise<void> {
    const db = admin.firestore();
    const today = new Date().toISOString().split('T')[0];  // YYYY-MM-DD

    const rateLimitRef = db.collection('rate_limits').doc(userId);
    const rateLimitDoc = await rateLimitRef.get();

    if (rateLimitDoc.exists) {
      const data = rateLimitDoc.data()!;

      // Check if same day
      if (data.date === today) {
        if (data.count >= MAX_REQUESTS_PER_DAY) {
          throw new functions.https.HttpsError(
            'resource-exhausted',
            `Daily AI request limit exceeded (${MAX_REQUESTS_PER_DAY} requests per day). Resets at midnight UTC.`
          );
        }

        // Increment counter
        await rateLimitRef.update({
          count: admin.firestore.FieldValue.increment(1)
        });
      } else {
        // New day, reset counter
        await rateLimitRef.set({
          date: today,
          count: 1
        });
      }
    } else {
      // First request
      await rateLimitRef.set({
        date: today,
        count: 1
      });
    }
  }
  ```
- [ ] Add rate limit check to all three Cloud Functions:
  ```typescript
  import { checkRateLimit } from './utils/rateLimiter';

  export const summarizeThread = functions.https.onCall(async (data, context) => {
    // Authentication check
    if (!context.auth) { ... }

    // Rate limit check
    await checkRateLimit(context.auth.uid);

    // Rest of function logic...
  });
  ```
- [ ] Create Firestore collection schema for `rate_limits/`:
  ```
  rate_limits/{userId}/
    ├── date: string (YYYY-MM-DD)
    ├── count: number
    └── lastRequestAt: timestamp
  ```
- [ ] Add security rule for `rate_limits` collection:
  ```javascript
  match /rate_limits/{userId} {
    allow read: if request.auth.uid == userId;
    allow write: if false;  // Only Cloud Functions write
  }
  ```

### Task 6: Implement Cost Tracking in Cloud Functions (AC: 5)

**Note:** iOS-side Analytics tracking is implemented in Task 6A (FirebaseAIService). This task focuses on Cloud Functions logging.

- [ ] Update Cloud Functions to log AI requests to Firestore:
  ```typescript
  // After successful AI API call
  await admin.firestore().collection('ai_usage_logs').add({
    userId: context.auth.uid,
    featureType: 'summary',  // or 'actionItems', 'search'
    conversationId: data.conversationId,
    model: 'gpt-4-turbo',
    tokensUsed: completion.usage?.total_tokens || 0,
    costEstimate: (completion.usage?.total_tokens || 0) * 0.00003,  // $0.03 per 1k tokens
    timestamp: admin.firestore.FieldValue.serverTimestamp(),
    cached: false
  });
  ```
- [ ] Create Firebase Analytics dashboard custom events:
  - [ ] `ai_summary_generated`
  - [ ] `ai_action_items_extracted`
  - [ ] `ai_smart_search`
  - [ ] `ai_rate_limit_exceeded`

### Task 6A: Create FirebaseAIService Wrapper with Analytics (AC: 5)

**Purpose:** High-level AI service that wraps CloudFunctionsService and adds Analytics tracking, error handling, and response mapping.

**Architecture Pattern:**
```
ViewModel → FirebaseAIService → CloudFunctionsService → Firebase Cloud Functions
            (Analytics, mapping)  (Network calls)
```

- [ ] Create `MessageAI/Data/Services/FirebaseAIService.swift`
- [ ] Implement complete service:
  ```swift
  // File: MessageAI/Data/Services/FirebaseAIService.swift

  import Foundation
  import FirebaseAnalytics

  /// High-level AI service that provides analytics tracking and error handling
  /// for AI features. Wraps CloudFunctionsService for actual network calls.
  class FirebaseAIService {
      private let cloudFunctionsService: CloudFunctionsService

      init(cloudFunctionsService: CloudFunctionsService) {
          self.cloudFunctionsService = cloudFunctionsService
      }

      /// Summarize a conversation thread with analytics tracking
      func summarizeThread(conversationId: String, messageIds: [String]?) async throws -> ThreadSummary {
          let startTime = Date()

          do {
              let response = try await cloudFunctionsService.callSummarizeThread(
                  conversationId: conversationId,
                  messageIds: messageIds
              )

              let duration = Date().timeIntervalSince(startTime)

              // Log successful request to Firebase Analytics
              Analytics.logEvent("ai_summary_generated", parameters: [
                  "conversation_id": conversationId,
                  "cached": response.cached,
                  "duration_ms": Int(duration * 1000),
                  "message_count": messageIds?.count ?? 0
              ])

              // Map Cloud Functions response to domain model
              return ThreadSummary(
                  summary: response.summary,
                  keyPoints: response.keyPoints ?? [],
                  participants: response.participants ?? [],
                  dateRange: response.dateRange,
                  generatedAt: response.timestamp,
                  cached: response.cached
              )

          } catch let error as AIServiceError where error == .rateLimitExceeded {
              // Log rate limit event
              Analytics.logEvent("ai_rate_limit_exceeded", parameters: [
                  "feature": "summary",
                  "conversation_id": conversationId
              ])
              throw error
          } catch {
              // Log error
              Analytics.logEvent("ai_error", parameters: [
                  "feature": "summary",
                  "error": error.localizedDescription
              ])
              throw error
          }
      }

      /// Extract action items from conversation with analytics tracking
      func extractActionItems(conversationId: String, messageIds: [String]?) async throws -> [ActionItem] {
          let startTime = Date()

          do {
              let response = try await cloudFunctionsService.callExtractActionItems(
                  conversationId: conversationId,
                  messageIds: messageIds
              )

              let duration = Date().timeIntervalSince(startTime)

              Analytics.logEvent("ai_action_items_extracted", parameters: [
                  "conversation_id": conversationId,
                  "action_item_count": response.actionItems.count,
                  "cached": response.cached,
                  "duration_ms": Int(duration * 1000)
              ])

              return response.actionItems.map { item in
                  ActionItem(
                      task: item.task,
                      assignee: item.assignee,
                      deadline: item.deadline,
                      sourceMessageId: item.sourceMessageId
                  )
              }

          } catch let error as AIServiceError where error == .rateLimitExceeded {
              Analytics.logEvent("ai_rate_limit_exceeded", parameters: [
                  "feature": "action_items",
                  "conversation_id": conversationId
              ])
              throw error
          } catch {
              Analytics.logEvent("ai_error", parameters: [
                  "feature": "action_items",
                  "error": error.localizedDescription
              ])
              throw error
          }
      }

      /// Generate smart search results with analytics tracking
      func generateSmartSearch(query: String, conversationIds: [String]) async throws -> [SearchResult] {
          let startTime = Date()

          do {
              let response = try await cloudFunctionsService.callGenerateSmartSearch(
                  query: query,
                  conversationIds: conversationIds
              )

              let duration = Date().timeIntervalSince(startTime)

              Analytics.logEvent("ai_smart_search", parameters: [
                  "query_length": query.count,
                  "result_count": response.results.count,
                  "cached": response.cached,
                  "duration_ms": Int(duration * 1000)
              ])

              return response.results.map { result in
                  SearchResult(
                      messageId: result.messageId,
                      conversationId: result.conversationId,
                      snippet: result.snippet,
                      relevanceScore: result.relevanceScore
                  )
              }

          } catch let error as AIServiceError where error == .rateLimitExceeded {
              Analytics.logEvent("ai_rate_limit_exceeded", parameters: [
                  "feature": "search",
                  "query": query
              ])
              throw error
          } catch {
              Analytics.logEvent("ai_error", parameters: [
                  "feature": "search",
                  "error": error.localizedDescription
              ])
              throw error
          }
      }
  }

  // MARK: - Domain Models

  struct ThreadSummary {
      let summary: String
      let keyPoints: [String]
      let participants: [String]
      let dateRange: String
      let generatedAt: Date
      let cached: Bool
  }

  struct ActionItem {
      let task: String
      let assignee: String
      let deadline: String?
      let sourceMessageId: String
  }

  struct SearchResult {
      let messageId: String
      let conversationId: String
      let snippet: String
      let relevanceScore: Double
  }
  ```

- [ ] Add FirebaseAIService to DIContainer:
  ```swift
  // File: MessageAI/App/DIContainer.swift

  func makeFirebaseAIService() -> FirebaseAIService {
      let cloudFunctionsService = makeCloudFunctionsService()
      return FirebaseAIService(cloudFunctionsService: cloudFunctionsService)
  }

  private func makeCloudFunctionsService() -> CloudFunctionsService {
      return CloudFunctionsService()
  }
  ```

- [ ] Update ViewModels to use FirebaseAIService (not CloudFunctionsService directly):
  ```swift
  // Example: ChatViewModel
  class ChatViewModel: ObservableObject {
      private let aiService: FirebaseAIService

      init(aiService: FirebaseAIService, ...) {
          self.aiService = aiService
          // ...
      }

      func summarizeThread() async {
          do {
              summary = try await aiService.summarizeThread(
                  conversationId: conversationId,
                  messageIds: nil
              )
          } catch let error as AIServiceError {
              errorMessage = error.errorDescription
          }
      }
  }
  ```

**Note:** This task was split from Task 6 to provide complete implementation guidance for the AI service wrapper layer.

### Task 7: User-Friendly Error Messages (AC: 6)

**Prerequisites Check:**
- [ ] Verify `CloudFunctionsService.swift` exists from Story 3.1 implementation
  - **Expected location:** `MessageAI/Data/Services/CloudFunctionsService.swift`
  - **If missing:** Create the file first (see Story 3.1 Task 7 for initial implementation)
  - **File purpose:** Low-level wrapper for calling Firebase Cloud Functions with authentication

- [ ] Update `MessageAI/Data/Services/CloudFunctionsService.swift` error mapping:
  ```swift
  // File: MessageAI/Data/Services/CloudFunctionsService.swift

  import Foundation
  import FirebaseFunctions

  enum AIServiceError: LocalizedError {
      case unauthenticated
      case rateLimitExceeded
      case serviceUnavailable
      case timeout
      case unknown(String)

      var errorDescription: String? {
          switch self {
          case .unauthenticated:
              return "Please sign in to use AI features."
          case .rateLimitExceeded:
              return "You've reached your daily limit of 100 AI requests. Please try again tomorrow."
          case .serviceUnavailable:
              return "AI service is temporarily unavailable. Please try again later."
          case .timeout:
              return "AI request took too long. Please try again with fewer messages."
          case .unknown(let message):
              return "An error occurred: \(message)"
          }
      }
  }

  func callSummarizeThread(...) async throws -> SummaryResponse {
      do {
          let result = try await functions.httpsCallable("summarizeThread").call(data)
          return try parseSummaryResponse(result.data)
      } catch let error as NSError {
          // Map Firebase Functions error codes to user-friendly errors
          if let code = FunctionsErrorCode(rawValue: error.code) {
              switch code {
              case .unauthenticated:
                  throw AIServiceError.unauthenticated
              case .resourceExhausted:
                  throw AIServiceError.rateLimitExceeded
              case .deadlineExceeded:
                  throw AIServiceError.timeout
              case .unavailable, .internal:
                  throw AIServiceError.serviceUnavailable
              default:
                  throw AIServiceError.unknown(error.localizedDescription)
              }
          }
          throw error
      }
  }
  ```
- [ ] Update ViewModels to display error messages:
  ```swift
  @Published var errorMessage: String?

  func summarizeThread() async {
      do {
          summary = try await aiService.summarizeThread(conversationId: conversationId)
      } catch let error as AIServiceError {
          errorMessage = error.errorDescription  // User-friendly message
      } catch {
          errorMessage = "An unexpected error occurred."
      }
  }
  ```

### Task 8: Implement Graceful Fallback Strategy (AC: 7)
- [ ] Update Cloud Functions to handle AI API failures gracefully:
  ```typescript
  try {
    const completion = await openai.chat.completions.create({ ... });
    return { success: true, summary: completion.choices[0].message.content };
  } catch (error) {
    // Log error but don't crash
    console.error('OpenAI API error:', error);

    if (error.status === 503) {
      throw new functions.https.HttpsError(
        'unavailable',
        'AI service is temporarily unavailable'
      );
    }

    throw new functions.https.HttpsError(
      'internal',
      'Failed to generate summary'
    );
  }
  ```
- [ ] Update iOS ViewModels to gracefully disable features:
  ```swift
  @Published var aiFeatureAvailable: Bool = true

  func summarizeThread() async {
      do {
          summary = try await aiService.summarizeThread(...)
      } catch AIServiceError.serviceUnavailable {
          aiFeatureAvailable = false
          errorMessage = "AI features are temporarily disabled. Basic messaging still works."
      }
  }
  ```
- [ ] Update UI to show degraded state:
  ```swift
  if !viewModel.aiFeatureAvailable {
      HStack {
          Image(systemName: "exclamationmark.triangle")
          Text("AI features temporarily unavailable")
      }
      .foregroundColor(.orange)
      .padding()
  }
  ```
- [ ] Ensure core messaging features continue to work when AI fails

### Task 9: Testing with Real AI Provider (AC: 10)
- [ ] Create test conversation with varied content:
  - [ ] 10-message thread with clear decision
  - [ ] 50-message thread with action items
  - [ ] 100-message thread for performance testing
  - [ ] Thread with emojis, code snippets, links
- [ ] Test `summarizeThread`:
  - [ ] Verify summary captures key points
  - [ ] Check summary length (150-300 words)
  - [ ] Validate no hallucinations
  - [ ] Test caching (2nd call instant)
- [ ] Test `extractActionItems`:
  - [ ] Create conversation with explicit tasks: "Can you send the report?"
  - [ ] Create conversation with implicit tasks: "I'll deploy tomorrow"
  - [ ] Verify assignees correctly identified
  - [ ] Verify sourceMessageId populated
  - [ ] Test function calling JSON parsing
- [ ] Test `generateSmartSearchResults`:
  - [ ] Natural language query: "What did Sarah say about deadlines?"
  - [ ] Keyword query: "Firebase"
  - [ ] Verify relevance ranking
  - [ ] Test synonym handling
- [ ] Test error scenarios:
  - [ ] Invalid API key (expect user-friendly error)
  - [ ] Rate limit exceeded (101st request in a day)
  - [ ] Network timeout (simulate slow connection)
  - [ ] Empty conversation (edge case)
- [ ] Test cost tracking:
  - [ ] Verify Firebase Analytics events logged
  - [ ] Check `ai_usage_logs` collection populated
  - [ ] Calculate estimated cost for 1000 requests

### Task 10: Documentation Updates (AC: 9)
- [ ] Create `docs/architecture/ai-provider.md`:
  ```markdown
  # AI Provider Configuration

  ## Selected Provider

  **Provider**: OpenAI
  **Model**: gpt-4-turbo
  **Rationale**: Function calling support, proven summarization quality, 128k context window

  ## API Access

  **API Key Storage**:
  - Cloud Functions: Firebase environment variables
  - iOS (testing only): iOS Keychain (not used in production)

  **Configuration**:
  \`\`\`bash
  firebase functions:config:set openai.api_key="sk-..." --project=messageai-dev-1f2ec
  \`\`\`

  ## Rate Limits

  - User limit: 100 requests per day
  - OpenAI limit: 10,000 tokens per minute (Tier 1)
  - Cost: ~$0.03 per 1k tokens

  ## Cost Estimates

  - Summary (500 tokens): $0.015
  - Action items (600 tokens): $0.018
  - Search (300 tokens): $0.009
  - Monthly (1000 users, 5 requests/user/month): ~$225

  ## Quality Thresholds

  - Summary: Must include all explicit decisions
  - Action items: 80%+ detection rate
  - Search: 90%+ relevant results in top 3
  ```
- [ ] Update `README.md` with AI setup section:
  - [ ] How to obtain OpenAI API key
  - [ ] How to configure Cloud Functions
  - [ ] How to test AI features locally
  - [ ] Rate limit information
- [ ] Update `functions/README.md`:
  - [ ] OpenAI SDK installation
  - [ ] Environment variable configuration
  - [ ] How to test with real API vs mocks
- [ ] Document rate limits and costs in user-facing docs (if needed)

### Task 11: Unit Tests for AI Integration (AC: 10)
- [ ] Update `functions/src/__tests__/summarizeThread.test.ts`:
  - [ ] Mock OpenAI API responses
  - [ ] Test successful summary generation
  - [ ] Test OpenAI rate limit error handling
  - [ ] Test invalid API key error
  - [ ] Test timeout handling
- [ ] Create `functions/src/__tests__/rateLimiter.test.ts`:
  - [ ] Test first request (creates rate limit doc)
  - [ ] Test incrementing counter
  - [ ] Test limit exceeded (101st request)
  - [ ] Test daily reset (new date)
- [ ] Create `MessageAITests/Data/Services/KeychainServiceTests.swift`:
  ```swift
  class KeychainServiceTests: XCTestCase {
      var keychainService: KeychainService!

      override func setUp() {
          keychainService = KeychainService.shared
      }

      override func tearDown() {
          try? keychainService.delete(key: "test-key")
      }

      func testSaveAndRetrieve() throws {
          try keychainService.save(key: "test-key", value: "test-value")
          let retrieved = try keychainService.retrieve(key: "test-key")
          XCTAssertEqual(retrieved, "test-value")
      }

      func testRetrieveNonExistent() throws {
          let retrieved = try keychainService.retrieve(key: "non-existent")
          XCTAssertNil(retrieved)
      }

      func testDelete() throws {
          try keychainService.save(key: "test-key", value: "test-value")
          try keychainService.delete(key: "test-key")
          let retrieved = try keychainService.retrieve(key: "test-key")
          XCTAssertNil(retrieved)
      }
  }
  ```
- [ ] Run all tests:
  ```bash
  # Cloud Functions tests (with mocked OpenAI)
  cd functions && npm test

  # iOS tests
  ./scripts/test-story.sh KeychainServiceTests
  ```

### Task 12: Security Rules Update for Rate Limits Collection
- [ ] Update `firestore.rules`:
  ```javascript
  // Rate limits collection
  match /rate_limits/{userId} {
    allow read: if isUser(userId);
    allow write: if false;  // Only Cloud Functions write
  }

  // AI usage logs collection (admin only)
  match /ai_usage_logs/{logId} {
    allow read: if false;  // Admin console only
    allow write: if false;  // Only Cloud Functions write
  }
  ```
- [ ] Deploy security rules:
  ```bash
  firebase deploy --only firestore:rules --project=messageai-dev-1f2ec
  ```
- [ ] Test rules with Firebase Emulator:
  - [ ] Verify users can read their own rate limit
  - [ ] Verify users cannot write to rate limits
  - [ ] Verify users cannot read usage logs

### Task 13: Deploy Updated Cloud Functions (AC: 3)

**Note:** Run after Task 11 (Unit Tests) and Task 12 (Security Rules) to ensure quality and proper permissions before deployment.

- [ ] Deploy to dev environment:
  ```bash
  firebase deploy --only functions --project=messageai-dev-1f2ec
  ```
- [ ] Verify deployment:
  - [ ] Check Firebase Console Functions tab
  - [ ] Verify environment variables set correctly
  - [ ] Test one function manually via Firebase Console
- [ ] Monitor logs for errors:
  ```bash
  firebase functions:log --only summarizeThread --project=messageai-dev-1f2ec
  ```
- [ ] Test from iOS app:
  - [ ] Point app to dev environment
  - [ ] Call `summarizeThread` from real conversation
  - [ ] Verify AI response received
  - [ ] Check Firebase Analytics for event

---

## Dev Notes

### AI Provider Selection Rationale

[Source: docs/architecture/tech-stack.md]

**Primary Choice: OpenAI GPT-4 Turbo**
- **Model**: `gpt-4-turbo` (128k context window)
- **Advantages**:
  - Function calling for structured outputs (action items, decisions)
  - Strong performance on summarization tasks
  - Well-documented SDK and API
  - Large context window (can handle 100+ message threads)
- **Pricing**: ~$0.03 per 1k tokens ($0.01 input, $0.03 output)
- **Rate Limits**: 10,000 TPM (Tier 1), 500 RPM

**Alternative: Anthropic Claude 3 Opus**
- **Model**: `claude-3-opus-20240229` (200k context window)
- **Advantages**:
  - Excellent summarization quality
  - Strong context understanding
  - Larger context window than GPT-4
- **Disadvantages**:
  - No native function calling (requires manual JSON parsing)
  - Newer SDK, less documentation
- **Use if**: OpenAI unavailable or quality testing shows Claude superior

### iOS Service Layer Architecture

[Source: Story 3.5 Task 6A, Clean Architecture principles]

**Service Layer Hierarchy:**
```
ViewModels (Presentation)
    ↓
FirebaseAIService (Data/Services)
    ↓ (wraps)
CloudFunctionsService (Data/Services)
    ↓ (calls)
Firebase Cloud Functions (Backend)
```

**Separation of Concerns:**
- **CloudFunctionsService**: Low-level network calls to Firebase Cloud Functions
  - Authentication token management
  - HTTP request/response handling
  - Network error mapping
  - File: `MessageAI/Data/Services/CloudFunctionsService.swift`

- **FirebaseAIService**: High-level AI feature wrapper
  - Firebase Analytics tracking
  - Domain model mapping (DTOs → Entities)
  - Business logic (caching, retry)
  - Error enrichment for user-facing messages
  - File: `MessageAI/Data/Services/FirebaseAIService.swift`

**Why Two Layers:**
- **Testability**: Can mock CloudFunctionsService in FirebaseAIService tests
- **Reusability**: CloudFunctionsService can be used for non-AI Cloud Functions
- **Single Responsibility**: Network concerns separate from business logic
- **Analytics**: Centralized AI analytics in one place (FirebaseAIService)

**Dependency Injection:**
```swift
// DIContainer.swift
func makeFirebaseAIService() -> FirebaseAIService {
    let cloudFunctionsService = makeCloudFunctionsService()
    return FirebaseAIService(cloudFunctionsService: cloudFunctionsService)
}

private func makeCloudFunctionsService() -> CloudFunctionsService {
    return CloudFunctionsService()
}
```

**ViewModel Usage:**
```swift
// ChatViewModel receives FirebaseAIService via DI
class ChatViewModel: ObservableObject {
    private let aiService: FirebaseAIService

    init(aiService: FirebaseAIService, ...) {
        self.aiService = aiService
    }

    func summarizeThread() async {
        do {
            let summary = try await aiService.summarizeThread(
                conversationId: conversationId,
                messageIds: nil
            )
            // Handle success
        } catch let error as AIServiceError {
            errorMessage = error.errorDescription  // User-friendly message
        }
    }
}
```

### API Key Security

[Source: docs/architecture/tech-stack.md#api-security]

**Cloud Functions (Production)**:
- API keys stored in Firebase environment variables
- Accessed via `functions.config().openai.api_key`
- Never exposed to client
- Set with: `firebase functions:config:set openai.api_key="sk-..."`

**iOS Keychain (Development/Testing Only)**:
- For local testing of AI features without deploying Cloud Functions
- Uses native iOS Keychain for secure storage
- **Not used in production** - all production AI calls go through Cloud Functions

**Security Best Practices**:
- Never commit API keys to git
- Never hardcode API keys in source code
- Use `.gitignore` for `.runtimeconfig.json` (local Cloud Functions testing)
- Rotate API keys periodically

### Rate Limiting Strategy

[Source: Epic 3 PRD Story 3.5 AC 4]

**User Limit**: 100 AI requests per day (configurable)

**Implementation**:
- Firestore collection: `rate_limits/{userId}`
- Schema: `{ date: "YYYY-MM-DD", count: number, lastRequestAt: timestamp }`
- Resets daily at midnight UTC
- Cloud Functions check limit before calling AI API

**Rationale**:
- Prevent cost overruns from abusive usage
- 100 requests/day = ~3000 requests/month per user
- At $0.03/request, max $90/month per user (extreme case)
- Typical usage: 5-10 requests/day = $1.50-$3/month per user

**Future Enhancements** (post-MVP):
- Tiered limits based on subscription plan
- Per-feature limits (e.g., 50 summaries, 30 searches per day)
- Organization-level limits for team plans

### Cost Tracking and Monitoring

[Source: docs/architecture/development-workflow-deployment.md#firebase-analytics, docs/architecture/tech-stack.md]

**Analytics Events**:
- `ai_summary_generated`: Track summary requests, cache hits, duration
- `ai_action_items_extracted`: Track action item extraction usage
- `ai_smart_search`: Track search queries and result counts
- `ai_rate_limit_exceeded`: Monitor users hitting limits

**Usage Logs**:
- Firestore collection: `ai_usage_logs`
- Schema: `{ userId, featureType, model, tokensUsed, costEstimate, timestamp, cached }`
- Used for cost analysis and optimization
- Admin-only access (not exposed to clients)

**Cost Calculation**:
```typescript
const costPerToken = 0.00003;  // $0.03 per 1k tokens (GPT-4 Turbo average)
const costEstimate = tokensUsed * costPerToken;
```

**Monitoring**:
- Firebase Console: Usage & Billing tab
- Firebase Analytics: Custom events dashboard
- Cloud Functions logs: Token usage per request
- Monthly cost reports from OpenAI dashboard

### Error Handling Patterns

[Source: docs/architecture/coding-standards.md#cloud-functions-coding-standards]

**OpenAI API Errors**:
- **401 Unauthorized**: Invalid API key → `failed-precondition` → "AI service not configured"
- **429 Rate Limited**: OpenAI rate limit → `resource-exhausted` → "AI service rate limit exceeded"
- **503 Service Unavailable**: OpenAI down → `unavailable` → "AI service temporarily unavailable"
- **Timeout**: > 60 seconds → `deadline-exceeded` → "AI request took too long"

**User-Facing Error Messages**:
- Never expose raw API errors to users
- Map technical errors to user-friendly messages
- Provide actionable guidance (e.g., "try again later", "reduce message count")
- Log technical details for debugging

**Fallback Strategy**:
1. **Cache-first**: Always check cache before calling AI
2. **Graceful degradation**: If AI fails, disable AI features but keep messaging working
3. **Retry logic**: For transient errors, retry with exponential backoff (handled by OpenAI SDK)
4. **User communication**: Show "AI features temporarily unavailable" banner

### OpenAI SDK Usage Patterns

**Basic Chat Completion**:
```typescript
const completion = await openai.chat.completions.create({
  model: 'gpt-4-turbo',
  messages: [
    { role: 'system', content: 'System prompt...' },
    { role: 'user', content: 'User prompt...' }
  ],
  temperature: 0.3,  // Lower = more deterministic
  max_tokens: 500    // Limit response length
});

const response = completion.choices[0].message.content;
const tokensUsed = completion.usage?.total_tokens || 0;
```

**Function Calling (Structured Output)**:
```typescript
const completion = await openai.chat.completions.create({
  model: 'gpt-4-turbo',
  messages: [...],
  tools: [{
    type: 'function',
    function: {
      name: 'extract_action_items',
      description: 'Extract action items from conversation',
      parameters: {
        type: 'object',
        properties: {
          actionItems: {
            type: 'array',
            items: { ... }
          }
        }
      }
    }
  }],
  tool_choice: { type: 'function', function: { name: 'extract_action_items' } }
});

const functionCall = completion.choices[0].message.tool_calls?.[0];
const result = JSON.parse(functionCall.function.arguments);
```

**Temperature Settings**:
- Summarization: 0.3 (more deterministic, factual)
- Action item extraction: 0.2 (structured, consistent)
- Search ranking: 0.2 (objective relevance)

### Firebase Analytics Integration

[Source: docs/architecture/development-workflow-deployment.md#firebase-analytics]

**Event Logging Pattern**:
```swift
import FirebaseAnalytics

Analytics.logEvent("ai_summary_generated", parameters: [
    "conversation_id": conversationId,
    "cached": response.cached,
    "duration_ms": Int(duration * 1000),
    "message_count": messageIds?.count ?? 0
])
```

**Custom Parameters**:
- `conversation_id`: Track which conversations use AI features
- `cached`: Monitor cache hit rate (target: 70%+)
- `duration_ms`: Performance tracking
- `message_count`: Correlate input size with performance

**Analytics Dashboard**:
- Firebase Console → Analytics → Events
- Create custom reports for AI feature usage
- Monitor daily active users of AI features
- Track conversion: How many users try AI features?

### iOS Keychain Service

[Source: docs/architecture/tech-stack.md#api-security]

**Purpose**: Secure storage for API keys during development/testing only

**Security Properties**:
- Encrypted storage tied to app bundle ID
- Data persists across app launches
- Protected by iOS Keychain security
- Not accessible by other apps

**Production Usage**: NOT used in production. All production AI calls route through Cloud Functions, which hold API keys in Firebase environment variables.

**Development Workflow**:
1. Store OpenAI API key in Keychain (one-time setup)
2. Test AI features locally without deploying Cloud Functions
3. Faster iteration during development

### Testing Strategy for AI Features

[Source: docs/architecture/testing-strategy.md, Epic 3 PRD Story 3.5 AC 10]

**Unit Tests (Mocked AI)**:
- Mock OpenAI API responses in Jest tests
- Test Cloud Functions logic (rate limiting, caching, error handling)
- Test KeychainService CRUD operations
- **Do NOT call real AI API in unit tests** (cost, speed)

**Integration Tests (Real AI)**:
- Create test conversations with known content
- Call Cloud Functions with real OpenAI API
- Validate response quality against acceptance criteria
- Measure performance (< 10 seconds)
- **Run sparingly** (costs money, slower)

**Quality Validation** (Manual Testing):
- 10-message thread: Verify summary captures decision
- 50-message thread: Verify action items detected
- 100-message thread: Performance testing
- Edge cases: Emojis, code snippets, empty threads

**Cost Management During Testing**:
- Use mocked responses for most tests
- Reserve real API calls for final validation
- Set OpenAI spending limit ($20/month for development)
- Monitor token usage in Firebase Analytics

### Performance Requirements

[Source: Epic 3 PRD, Epic 3 Scope]

**Response Time Targets**:
- First request (AI call): < 10 seconds
- Cached request: < 1 second
- Rate limit check: < 100ms overhead

**Token Usage Estimates**:
- Summary (100 messages, 500 tokens response): ~2000 tokens total
- Action items (50 messages, 600 tokens response): ~1500 tokens total
- Search (query + 100 messages, 300 tokens response): ~1200 tokens total

**Cost per Request**:
- Summary: ~$0.015
- Action items: ~$0.018
- Search: ~$0.009

**Cache Hit Rate Goal**: 70%+ (reduces costs by 70%)

### Firestore Collections Added

**rate_limits/**:
```
{
  date: string (YYYY-MM-DD)
  count: number
  lastRequestAt: timestamp
}
```
- Purpose: Track user AI request counts per day
- Security: User can read own, only Cloud Functions write

**ai_usage_logs/**:
```
{
  userId: string
  featureType: string (summary|actionItems|search)
  conversationId: string
  model: string (gpt-4-turbo)
  tokensUsed: number
  costEstimate: number
  timestamp: timestamp
  cached: boolean
}
```
- Purpose: Cost tracking and analytics
- Security: Admin-only access

### Related Architecture Documents

- [Tech Stack](../architecture/tech-stack.md) - AI provider selection and Keychain usage
- [Coding Standards](../architecture/coding-standards.md#cloud-functions-coding-standards) - Error handling and validation
- [Development Workflow](../architecture/development-workflow-deployment.md) - Firebase Analytics patterns
- [Database Schema](../architecture/database-schema.md) - ai_cache, rate_limits, ai_usage_logs collections

---

## Testing

[Source: docs/architecture/testing-strategy.md]

### Unit Tests

**Cloud Functions Tests** (`functions/src/__tests__/*.test.ts`):

```typescript
// Mock OpenAI SDK
jest.mock('openai', () => {
  return {
    OpenAI: jest.fn().mockImplementation(() => ({
      chat: {
        completions: {
          create: jest.fn().mockResolvedValue({
            choices: [{ message: { content: 'Test summary' } }],
            usage: { total_tokens: 500 }
          })
        }
      }
    }))
  };
});

describe('summarizeThread with OpenAI', () => {
  it('should call OpenAI API with correct parameters', async () => {
    // Test OpenAI API call
    // Verify prompt format
    // Check token usage logging
  });

  it('should handle OpenAI rate limit error', async () => {
    // Mock 429 error
    // Expect resource-exhausted error
  });
});

describe('rateLimiter', () => {
  it('should allow first request', async () => {
    await checkRateLimit('user-1');
    // Verify rate_limits document created with count=1
  });

  it('should reject 101st request in same day', async () => {
    // Mock existing rate limit doc with count=100
    await expect(checkRateLimit('user-1')).rejects.toThrow('resource-exhausted');
  });

  it('should reset counter on new day', async () => {
    // Mock existing rate limit doc with yesterday's date
    await checkRateLimit('user-1');
    // Verify count reset to 1, date updated
  });
});
```

**iOS Tests** (`MessageAITests/Data/Services/KeychainServiceTests.swift`):

```swift
func testSaveAndRetrieve() throws {
    try keychainService.save(key: "openai_key", value: "sk-test123")
    let retrieved = try keychainService.retrieve(key: "openai_key")
    XCTAssertEqual(retrieved, "sk-test123")
}

func testOverwriteExistingKey() throws {
    try keychainService.save(key: "test", value: "value1")
    try keychainService.save(key: "test", value: "value2")
    let retrieved = try keychainService.retrieve(key: "test")
    XCTAssertEqual(retrieved, "value2")
}
```

### Integration Tests

**Real AI API Testing** (Manual, before marking story complete):

1. **Setup**:
   ```bash
   # Set real API key
   firebase functions:config:set openai.api_key="sk-..." --project=messageai-dev-1f2ec

   # Deploy functions
   firebase deploy --only functions --project=messageai-dev-1f2ec
   ```

2. **Test Scenarios**:
   - Create conversation with 10 messages
   - Call `summarizeThread` from iOS app
   - Verify summary quality:
     - [ ] Captures main topic
     - [ ] Mentions all participants
     - [ ] Includes key points
     - [ ] Length: 150-300 words
   - Call again, verify cache hit (< 1 second)

3. **Rate Limit Testing**:
   - Make 100 AI requests in succession
   - Verify 101st request fails with rate limit error
   - Verify error message is user-friendly
   - Wait until next day (UTC), verify counter reset

4. **Cost Tracking Validation**:
   - Check `ai_usage_logs` collection populated
   - Verify Firebase Analytics events logged
   - Calculate total cost for 100 requests
   - Verify cost matches OpenAI dashboard

### Performance Testing

**Baseline Measurements**:
```swift
func testSummarizePerformance() async throws {
    let startTime = Date()

    let summary = try await aiService.summarizeThread(
        conversationId: "test-conversation",
        messageIds: nil  // Last 100 messages
    )

    let duration = Date().timeIntervalSince(startTime)

    XCTAssertLessThan(duration, 10.0, "Summary should complete within 10 seconds")
    XCTAssertFalse(summary.summary.isEmpty)
}

func testCachedSummaryPerformance() async throws {
    // First call (uncached)
    _ = try await aiService.summarizeThread(conversationId: "test")

    // Second call (should be cached)
    let startTime = Date()
    let summary = try await aiService.summarizeThread(conversationId: "test")
    let duration = Date().timeIntervalSince(startTime)

    XCTAssertLessThan(duration, 1.0, "Cached summary should return within 1 second")
    XCTAssertTrue(summary.cached)
}
```

### Testing Workflow

**During Development**:
```bash
# Unit tests (mocked OpenAI) - run frequently
cd functions && npm test

# iOS Keychain tests
./scripts/test-story.sh KeychainServiceTests
```

**Before Marking Story Complete**:
```bash
# Deploy Cloud Functions with real API key
firebase deploy --only functions --project=messageai-dev-1f2ec

# Manual integration testing (see Integration Tests above)

# Run full test suite
./scripts/quick-test.sh
```

**Quality Validation Checklist**:
- [ ] 5 test conversations created
- [ ] All summaries capture key decisions (8/10 threshold)
- [ ] All action items detected (7/10 with 80%+ detection)
- [ ] Search returns relevant results (9/10 with top 3 relevant)
- [ ] Rate limiting works (101st request blocked)
- [ ] Cost tracking logs complete
- [ ] Error messages user-friendly
- [ ] Fallback strategy tested (OpenAI down scenario)

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-22 | 1.0 | Initial story draft created | Scrum Master (Bob) |
| 2025-10-22 | 1.1 | PO validation fixes applied: Added Task 6A (FirebaseAIService), clarified CloudFunctionsService file path in Task 7, reordered tasks 12-13, added iOS Service Layer Architecture to Dev Notes | Product Owner (Sarah) |

---

## Dev Agent Record

### Agent Model Used

_To be filled by Dev Agent_

---

### Debug Log References

_To be filled by Dev Agent_

---

### Completion Notes List

_To be filled by Dev Agent_

---

### File List

_To be filled by Dev Agent_

---

## QA Results

_To be filled by QA Agent_
