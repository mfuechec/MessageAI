# Story 6.3: AI Notification Analysis Cloud Function

## Status

**Draft**

---

## Story

**As a** user,
**I want** AI to intelligently decide which conversations deserve notifications,
**so that** I only get notified about truly important messages, not general chatter.

---

## Acceptance Criteria

**Cloud Function: analyzeForNotification**
1. Function signature: `analyzeForNotification(conversationId: String, userId: String) -> NotificationDecision`
2. Returns: `{ shouldNotify: Bool, reason: String, notificationText: String, priority: "high" | "medium" | "low" }`
3. Authentication: Validates Firebase Auth token, verifies user is conversation participant
4. Input validation: Checks conversationId exists, userId valid, conversation has unread messages

**AI Analysis Logic:**
5. Step 1: Fetch recent conversation messages (last 30 messages or 15 minutes, whichever is fewer)
6. Step 2: Filter to unread messages for this user (don't analyze already-read content)
7. Step 3: Retrieve user context via RAG (Story 6.2 dependencies)
8. Step 4: Call OpenAI GPT-4 with structured prompt (see below)
9. Step 5: Parse JSON response, validate structure

**LLM Prompt Structure:**
10. System prompt includes:
    - Role: "Notification assistant for remote team professionals"
    - Notification criteria: Mentions, urgent requests, direct questions, decisions affecting user, blockers, production issues
    - Non-notification criteria: General chat, FYI updates user isn't involved in, social/casual conversation
    - Output format: JSON with shouldNotify, reason, notificationText, priority
11. User context included: User's recent activity, preferences, active hours, priority keywords
12. Conversation context: Last N messages formatted with sender names, timestamps, message text
13. Temperature: 0.3 (more deterministic, consistent decisions)

**Notification Decision Quality:**
14. **Must notify:** Direct @mentions of user (100% notification rate)
15. **Must notify:** Direct questions to user ("Can you...", "Could you...", "Would you...")
16. **Must notify:** Decisions affecting user's work (detected via context: project names, user responsibilities)
17. **Should notify:** Urgent/time-sensitive keywords in user's priority list (default: "urgent", "ASAP", "production down", "blocker")
18. **Should not notify:** General team chat not involving user
19. **Should not notify:** Social/casual messages ("lol", "thanks!", emoji reactions)

**Notification Text Generation:**
20. Notification text clear and actionable: "Sarah mentioned you: 'Can you review the API design?'"
21. Notification text includes sender and key context
22. Notification text max 100 characters (iOS/Android limits)
23. Priority level affects iOS notification presentation (high = banner, medium = notification center, low = badge only)

**Caching & Cost Optimization:**
24. Check cache before LLM call: cacheKey = `notification_${conversationId}_${unreadMessagesHash}`
    - Where unreadMessagesHash = SHA256 hash of unread message IDs for this user (sorted)
    - Cache only invalidates when NEW unread messages arrive (not all messages)
25. Cache hit: Return cached decision (< 1 second)
26. Cache miss: Call LLM, cache result with 1-hour expiration
27. Cache TTL: Cache expires after 1 hour OR when new unread messages arrive, whichever comes first

**Error Handling:**
28. OpenAI rate limit (429): Return `{ shouldNotify: false, reason: "AI temporarily unavailable" }`
29. Timeout (>10 seconds): Return fallback decision based on simple heuristics (mentions = notify)
30. Network error: Log error, return `{ shouldNotify: false }`
31. Invalid response from LLM: Retry once, then fallback to heuristics

**Fallback Heuristics (when AI unavailable):**
32. If message contains "@username" where username = current user → notify (high priority)
33. If message contains priority keywords → notify (medium priority)
34. If message is direct question (ends with "?") and mentions user → notify (medium priority)
35. Otherwise → don't notify

**Testing:**
36. Unit test: Mock OpenAI responses with recorded JSON fixtures. Test prompt structure and context formatting, NOT LLM behavior.
37. Unit test: JSON parsing handles all expected response formats (valid, missing fields, malformed)
38. Integration test: Use recorded LLM responses (fixtures). Verify client correctly parses and applies decision.
39. Integration test: Test fallback heuristics directly (bypass LLM). Verify direct mention triggers notify.
40. Integration test: Test fallback heuristics directly. Verify general chat triggers no notify.
41. Integration test: Cache hit returns instantly (< 1 second) - use real cache, mock LLM
42. Integration test: AI unavailable (mock 429 error) falls back to heuristics
43. Performance test: Analysis completes within 8 seconds (including RAG)
44. Manual validation: Test with 10 sample conversations, manually verify AI decisions make sense

---

## Tasks / Subtasks

- [ ] Create analyzeForNotification Cloud Function (AC: 1-4)
  - [ ] Create `functions/src/analyzeForNotification.ts`
  - [ ] Export as `onCall` function with authentication check
  - [ ] Validate input parameters: conversationId, userId
  - [ ] Verify user is participant in conversation (Firestore query)
  - [ ] Return error if user not authorized

- [ ] Implement conversation data fetching (AC: 5-6)
  - [ ] Query Firestore for recent messages (last 30 or 15 minutes)
  - [ ] Filter to unread messages: `!message.readBy.includes(userId)`
  - [ ] If no unread messages, return `{ shouldNotify: false, reason: "No unread messages" }`
  - [ ] Format messages for LLM context

- [ ] Integrate RAG system (AC: 7, Story 6.2 dependency)
  - [ ] Import `getUserRecentContext` from Story 6.2
  - [ ] Import `findRelevantMessages` from Story 6.2
  - [ ] Fetch user's recent activity (last 100 messages, 7 days)
  - [ ] Perform semantic search for related past conversations
  - [ ] Load user notification preferences

- [ ] Design LLM prompt (AC: 10-13)
  - [ ] Create `functions/src/prompts/notification-analysis-prompt.ts`
  - [ ] Define system prompt template
  - [ ] Define user context formatting
  - [ ] Define conversation formatting
  - [ ] Include notification criteria and examples
  - [ ] Specify JSON output schema

- [ ] Implement OpenAI GPT-4 call (AC: 8-9)
  - [ ] Use `openai.chat.completions.create()` with GPT-4 model
  - [ ] Set temperature: 0.3
  - [ ] Set response_format: `{ type: "json_object" }`
  - [ ] Parse JSON response
  - [ ] Validate response structure matches NotificationDecision schema

- [ ] Implement notification decision logic (AC: 14-19)
  - [ ] Validate LLM identifies direct @mentions (must notify)
  - [ ] Validate LLM identifies direct questions (must notify)
  - [ ] Validate LLM identifies urgent keywords (should notify)
  - [ ] Validate LLM suppresses general chat (should not notify)
  - [ ] Test with 10 sample conversations covering all criteria

- [ ] Implement notification text generation (AC: 20-23)
  - [ ] Extract sender name from message
  - [ ] Format notification text: "{Sender}: {message snippet}"
  - [ ] Truncate to 100 characters max
  - [ ] Set priority level based on LLM decision

- [ ] Implement caching layer (AC: 24-27)
  - [ ] Create Firestore collection: `ai_notification_cache`
  - [ ] Generate cache key: hash of conversationId + latestMessageId
  - [ ] Check cache before calling LLM
  - [ ] Store result in cache with 1-hour TTL
  - [ ] Invalidate cache on new messages (Firestore trigger)

- [ ] Implement error handling (AC: 28-31)
  - [ ] Catch OpenAI rate limit errors (status 429)
  - [ ] Implement timeout after 10 seconds
  - [ ] Retry logic: Retry once on network error
  - [ ] Log all errors to Firebase Logging

- [ ] Implement fallback heuristics (AC: 32-35)
  - [ ] Create `functions/src/helpers/fallback-notification-logic.ts`
  - [ ] Detect @mentions using regex
  - [ ] Detect priority keywords in message text
  - [ ] Detect direct questions (ends with "?")
  - [ ] Return simple decision based on heuristics

- [ ] Write unit tests (AC: 36-37)
  - [ ] Test: Prompt includes user context correctly
  - [ ] Test: JSON response parsing handles all formats
  - [ ] Test: Fallback heuristics detect mentions correctly
  - [ ] Test: Fallback heuristics detect questions correctly
  - [ ] Test: Cache key generation is consistent

- [ ] Write integration tests (AC: 38-42)
  - [ ] Test: Direct mention returns shouldNotify=true
  - [ ] Test: General chat returns shouldNotify=false
  - [ ] Test: Urgent keyword returns shouldNotify=true with medium priority
  - [ ] Test: Cache hit returns < 1 second
  - [ ] Test: AI unavailable falls back to heuristics
  - [ ] Test: User not in conversation returns error

- [ ] Performance testing (AC: 43)
  - [ ] Measure end-to-end latency (target: < 8 seconds)
  - [ ] Measure cache hit latency (target: < 1 second)
  - [ ] Measure RAG overhead (Story 6.2: < 3 seconds)
  - [ ] Measure LLM call latency (typical: 3-5 seconds)
  - [ ] Optimize if performance targets not met

---

## Dev Notes

### Architecture Context

**Cloud Function Flow:**
```
analyzeForNotification (onCall)
  ↓
1. Authenticate & Validate
  ↓
2. Check Cache (ai_notification_cache)
  ↓ (cache miss)
3. Fetch Conversation Messages (Firestore)
  ↓
4. Load User Context (RAG - Story 6.2)
  ↓
5. Build LLM Prompt
  ↓
6. Call OpenAI GPT-4
  ↓
7. Parse JSON Response
  ↓
8. Store in Cache
  ↓
9. Return NotificationDecision
```

**Fallback on Error:**
```
LLM Error (rate limit, timeout, network)
  ↓
Log Error
  ↓
Apply Fallback Heuristics
  ↓
Return Simple Decision
```

### Relevant Source Tree

**New Files:**
- `functions/src/analyzeForNotification.ts` - Main Cloud Function
- `functions/src/prompts/notification-analysis-prompt.ts` - LLM prompt templates
- `functions/src/helpers/fallback-notification-logic.ts` - Simple heuristics
- `functions/test/analyzeForNotification.test.ts` - Unit tests
- `functions/test/integration/notification-analysis.test.ts` - Integration tests

**Modified Files:**
- `functions/src/index.ts` - Export analyzeForNotification
- `firestore.rules` - Add rules for ai_notification_cache collection

### Key Technical Decisions

**1. LLM Model Selection:**
Use OpenAI GPT-4 (not GPT-3.5):
- **Why:** Better context understanding, fewer hallucinations, more consistent decisions
- **Cost:** ~$0.03 per 1K tokens (input) + $0.06 per 1K tokens (output)
- **Typical request:** ~2K tokens input + 200 tokens output = ~$0.08 per analysis
- **With 60% cache hit rate:** Effective cost ~$0.03 per analysis

**2. Structured JSON Output:**
```typescript
{
  shouldNotify: boolean,
  reason: string, // AI's reasoning for decision
  notificationText: string, // User-facing notification text
  priority: "high" | "medium" | "low"
}
```

Use OpenAI's `response_format: { type: "json_object" }` to guarantee JSON output.

**3. System Prompt Template:**
```typescript
const SYSTEM_PROMPT = `You are a notification assistant for remote team professionals. Your job is to analyze conversation messages and decide if the user should be notified.

ALWAYS NOTIFY if:
- User is directly mentioned (@username or by name)
- User is asked a direct question ("Can you...", "Could you...", "Would you...")
- A decision is made that affects the user's work or responsibilities
- There's an urgent/time-sensitive request related to user's projects
- Production issue or blocker is mentioned that affects user

NEVER NOTIFY if:
- General team chat that doesn't involve the user
- FYI updates the user isn't responsible for
- Social/casual conversation (jokes, "thanks", emoji reactions)
- Information already known to user (based on user context)

User Context:
{userContext}

User Preferences:
- Active hours: {activeHours}
- Priority keywords: {priorityKeywords}

Conversation Messages:
{messages}

Respond ONLY with JSON in this format:
{
  "shouldNotify": true/false,
  "reason": "brief explanation of decision",
  "notificationText": "clear, actionable notification text (max 100 chars)",
  "priority": "high" | "medium" | "low"
}`;
```

**4. Message Formatting:**
```typescript
function formatMessagesForLLM(messages: Message[]): string {
  return messages.map(msg =>
    `[${msg.timestamp.toISOString()}] ${msg.senderName}: ${msg.text}`
  ).join('\n');
}
```

**5. Caching Strategy (Improved for Better Hit Rate):**
```typescript
import crypto from 'crypto';

// Cache key includes conversationId + hash of unread message IDs
// Only invalidates when NEW unread messages arrive (not all messages)
function generateCacheKey(conversationId: string, unreadMessageIds: string[]): string {
  // Sort for consistency
  const sortedIds = unreadMessageIds.sort();

  // Hash the unread message IDs
  const hash = crypto.createHash('sha256')
    .update(sortedIds.join(','))
    .digest('hex')
    .substring(0, 16); // First 16 chars sufficient

  return `notification_${conversationId}_${hash}`;
}

// Cache entry
{
  cacheKey: string,
  decision: NotificationDecision,
  unreadMessageIds: string[], // Store for validation
  createdAt: Timestamp,
  expiresAt: Timestamp // +1 hour
}

// Cache invalidation: Only when new unread messages arrive for this user
// Result: Higher cache hit rate (60% → 75%+)
```

**6. Fallback Heuristics:**
```typescript
function fallbackNotificationDecision(
  messages: Message[],
  userId: string,
  preferences: NotificationPreferences
): NotificationDecision {
  // Check for @mention
  const hasMention = messages.some(msg =>
    msg.text.includes(`@${userId}`) || msg.text.includes(`@${userName}`)
  );
  if (hasMention) {
    return {
      shouldNotify: true,
      reason: "User mentioned (fallback heuristic)",
      notificationText: extractMentionText(messages),
      priority: "high"
    };
  }

  // Check for priority keywords
  const hasPriorityKeyword = messages.some(msg =>
    preferences.priorityKeywords.some(keyword =>
      msg.text.toLowerCase().includes(keyword.toLowerCase())
    )
  );
  if (hasPriorityKeyword) {
    return {
      shouldNotify: true,
      reason: "Priority keyword detected (fallback)",
      notificationText: extractPriorityText(messages),
      priority: "medium"
    };
  }

  // Default: Don't notify
  return {
    shouldNotify: false,
    reason: "No notification triggers found (fallback)",
    notificationText: "",
    priority: "low"
  };
}
```

**7. Performance Optimization:**
- Parallel execution: Fetch messages, user context, and cache check concurrently
- Message limit: Only analyze last 30 messages (reduces token cost + processing time)
- User context caching: 10-minute TTL (Story 6.2)
- Notification decision caching: 1-hour TTL (this story)

```typescript
// Parallel fetching
const [messages, userContext, cachedDecision] = await Promise.all([
  fetchRecentMessages(conversationId, 30),
  getUserRecentContext(userId),
  checkCache(cacheKey)
]);

if (cachedDecision && !isCacheExpired(cachedDecision)) {
  return cachedDecision.decision; // < 1 second
}
```

### Cost Estimation

**Per Analysis (No Cache):**
- RAG context retrieval: $0.0004 (Story 6.2)
- GPT-4 LLM call: ~$0.08 (2K input tokens + 200 output tokens)
- Firestore writes (cache): $0.00018
- **Total: ~$0.08 per analysis**

**With 60% Cache Hit Rate:**
- 60% cache hits: $0.0004 (just Firestore read)
- 40% cache misses: $0.08
- **Effective cost: 0.6 * $0.0004 + 0.4 * $0.08 = ~$0.032 per analysis**

**Monthly Cost (1000 users, 10 analyses/user/day):**
- 1000 users * 10 analyses/day * 30 days * $0.032 = **$9,600/month**

Note: This is a demo. Production would need:
- Lower analysis frequency (smarter triggers)
- Higher cache hit rate (>80%)
- Batch processing for multiple users
- Or use cheaper model (GPT-3.5: ~$0.003 per analysis)

### Notification Decision Examples

**Example 1: Direct Mention (Must Notify)**
```
Input:
User: alice@example.com
Messages:
  - [10:15] Bob: "Hey team, we need to finalize the API design"
  - [10:16] Sarah: "@Alice can you review the endpoints?"

Output:
{
  "shouldNotify": true,
  "reason": "User directly mentioned in conversation",
  "notificationText": "Sarah mentioned you: Can you review the endpoints?",
  "priority": "high"
}
```

**Example 2: General Chat (Should Not Notify)**
```
Input:
User: alice@example.com
Messages:
  - [10:15] Bob: "Great job on the demo!"
  - [10:16] Sarah: "Thanks! 🎉"

Output:
{
  "shouldNotify": false,
  "reason": "Social conversation not involving user",
  "notificationText": "",
  "priority": "low"
}
```

**Example 3: Urgent Keyword (Should Notify)**
```
Input:
User: alice@example.com
Preferences: priorityKeywords = ["production down", "urgent"]
Messages:
  - [10:15] Bob: "Production down! Database connection failing"

Output:
{
  "shouldNotify": true,
  "reason": "Urgent priority keyword detected affecting user's area",
  "notificationText": "Bob: Production down! Database connection failing",
  "priority": "high"
}
```

### Testing LLM-Based Logic

**CRITICAL: DO NOT test LLM output directly** - it's non-deterministic even with temperature=0.3.

**Test Strategy:**
1. **Unit tests:** Mock OpenAI client, return fixtures, test parsing logic
2. **Integration tests:** Use recorded responses from real LLM calls (fixtures)
3. **Manual validation:** Test with 10 sample conversations, manually verify decisions
4. **Fallback tests:** Test heuristics directly (no LLM involved) - these ARE deterministic

**Why this approach:**
- LLMs can return slightly different outputs even with same input + low temperature
- Testing "direct mention always returns shouldNotify=true" will be flaky
- Instead: Test that our **parsing** of LLM responses works correctly
- Use **fallback heuristics** as the deterministic test surface

**Example:**
```typescript
// ❌ BAD TEST (flaky)
it('should notify on direct mention', async () => {
  const result = await analyzeForNotification({ conversationId: 'conv123', userId: 'alice' });
  expect(result.shouldNotify).toBe(true); // Fails sometimes!
});

// ✅ GOOD TEST (deterministic)
it('should parse LLM response correctly', async () => {
  mockOpenAI.returnFixture('mention-response.json'); // Recorded response
  const result = await analyzeForNotification({ conversationId: 'conv123', userId: 'alice' });
  expect(result.shouldNotify).toBe(true);
  expect(result.priority).toBe('high');
});

// ✅ GOOD TEST (fallback heuristics)
it('fallback heuristics detect mention', () => {
  const messages = [{ text: '@alice can you help?', senderId: 'bob' }];
  const decision = fallbackNotificationDecision(messages, 'alice', preferences);
  expect(decision.shouldNotify).toBe(true);
});
```

### Testing Standards

**Test File Location:**
- Unit tests: `functions/test/analyzeForNotification.test.ts`
- Integration tests: `functions/test/integration/notification-analysis.test.ts`
- Fixtures: `functions/test/fixtures/llm-responses/`

**Testing Frameworks:**
- Jest for Cloud Functions unit tests
- Firebase Emulator Suite for integration tests
- Mock OpenAI responses for unit tests (use recorded responses from `fixtures/`)

**Test Coverage Requirements:**
- analyzeForNotification function: 80%+ coverage
- Fallback heuristics: 90%+ coverage (critical path)

**Testing Patterns:**
```typescript
// functions/test/analyzeForNotification.test.ts
import { analyzeForNotification } from '../src/analyzeForNotification';
import { mockOpenAI } from './mocks/openai';

describe('analyzeForNotification', () => {
  beforeEach(() => {
    mockOpenAI.resetHistory();
  });

  it('should notify on direct mention', async () => {
    // Setup test conversation with @mention
    const result = await analyzeForNotification({
      conversationId: 'conv123',
      userId: 'alice'
    });

    expect(result.shouldNotify).toBe(true);
    expect(result.priority).toBe('high');
  });

  it('should not notify on general chat', async () => {
    // Setup test conversation with social messages
    const result = await analyzeForNotification({
      conversationId: 'conv123',
      userId: 'alice'
    });

    expect(result.shouldNotify).toBe(false);
  });

  it('should fallback on AI error', async () => {
    // Mock OpenAI to throw rate limit error
    mockOpenAI.throwError(429);

    const result = await analyzeForNotification({
      conversationId: 'conv123',
      userId: 'alice'
    });

    // Should use fallback heuristics
    expect(result.reason).toContain('fallback');
  });
});
```

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-23 | 1.0 | Initial story creation | Sarah (PO) |

---

## Dev Agent Record

### Agent Model Used

_To be populated by dev agent_

### Debug Log References

_To be populated by dev agent_

### Completion Notes List

_To be populated by dev agent_

### File List

_To be populated by dev agent_

---

## QA Results

_To be populated by QA agent_
